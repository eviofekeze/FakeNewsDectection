{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWwaZI_GE4cr"
      },
      "source": [
        "## Detecting Fake News and Real News"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8TgA-75E4cv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import re\n",
        "import textstat as ts\n",
        "import xgboost as xg\n",
        "from sklearn import svm\n",
        "import csv\n",
        "\n",
        "import scipy.sparse\n",
        "import scipy.sparse.csgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mAufzXaxtwk"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD, NMF\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, recall_score, make_scorer, roc_auc_score, average_precision_score, precision_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSvxpMKYE4c6"
      },
      "source": [
        "### Politifact: Load and Format News Content Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi15DxChE4c8",
        "outputId": "6ae051bf-a48e-48ee-97c1-37f64f433e28"
      },
      "outputs": [],
      "source": [
        "#get real news content data\n",
        "temp = pd.read_json('PolitiFact/RealNewsContent/PolitiFact_Real_2-Webpage.json',orient='index')\n",
        "pf_real_news =  pd.DataFrame(columns=temp.index)\n",
        "for i in range(1,121):\n",
        "    path='PolitiFact/RealNewsContent/PolitiFact_Real_'+str(i)+'-Webpage.json'\n",
        "    df = pd.read_json(path,orient='index')\n",
        "    df = df.transpose()\n",
        "    pf_real_news = pd.concat([pf_real_news, df])\n",
        "del(df,path,i)\n",
        "\n",
        "\n",
        "#get fake news content data\n",
        "pf_fake_news =  pd.DataFrame(columns=temp.index)\n",
        "for i in range(1,121):\n",
        "    path='PolitiFact/FakeNewsContent/PolitiFact_Fake_'+str(i)+'-Webpage.json'\n",
        "    df = pd.read_json(path,orient='index')\n",
        "    df = df.transpose()\n",
        "    pf_fake_news = pd.concat([pf_fake_news, df])\n",
        "\n",
        "del(df,path,i,temp)\n",
        "\n",
        "\n",
        "#Assing Classe\n",
        "pf_fake_news['Real'] = 0\n",
        "pf_real_news['Real'] = 1\n",
        "\n",
        "print(pf_real_news.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pf_real_news = pf_real_news.reset_index(drop=True)\n",
        "pf_fake_news.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Dc2Y1J5E4dW"
      },
      "source": [
        "There are two news content sets for stories categorized by Politifact one consisting of fake and real stories. Both data sets contain 120 stories with the same 13 fields for each. Above is an informational readout for the Politifact fake news data with the name of each field where the names are mostly self-expanatory. Note that the text column contains the entire text of the news article.\n",
        "\n",
        "### Politifact: Load and Format User/Network Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ClEeyiFE4dZ",
        "outputId": "c4738612-eb82-4026-e809-3676d2f92360"
      },
      "outputs": [],
      "source": [
        "# get user info data\n",
        "pf_news = pd.read_csv('PolitiFact/News.txt',header=None,names=['news'])\n",
        "pf_users = pd.read_csv('PolitiFact/User.txt',header=None,names=['users'])\n",
        "pf_news_user = pd.read_csv('PolitiFact/PolitiFactNewsUser.txt',header=None,names=['news_users'])\n",
        "pf_user_user = pd.read_csv('PolitiFact/PolitiFactUserUser.txt',header=None,names=['followers'])\n",
        "\n",
        "# build graph\n",
        "G_pf = nx.DiGraph()\n",
        "G_pf.add_nodes_from(pf_users)\n",
        "G_pf.add_edges_from(pf_user_user['followers'].str.split('\\t'))\n",
        "print('The number of nodes in the network is ',G_pf.number_of_nodes())\n",
        "print('The number of edges in the network is ',G_pf.number_of_edges())\n",
        "print('The number of user-news relationships is', len(pf_news_user))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdt2HHJtUKaS"
      },
      "source": [
        "There are 23,866 distinct twitter users represented in the data set. \n",
        "\n",
        "There are 574,744 user relationships that represent who is following who. \n",
        "\n",
        "Finally there are 32,791 user-news relationships that tell which user shared which story and how many times the story was shared.\n",
        "\n",
        "### BuzzFeed: Load and Format News Content Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98lTOETjUOZq",
        "outputId": "4e754c33-8aa0-4dbd-9f41-ea7815c856fe"
      },
      "outputs": [],
      "source": [
        "#get real news content data\n",
        "temp = pd.read_json('BuzzFeed/RealNewsContent/BuzzFeed_Real_2-Webpage.json',orient='index')\n",
        "bf_real_news =  pd.DataFrame(columns=temp.index)\n",
        "for i in range(1,92):\n",
        "    path='BuzzFeed/RealNewsContent/BuzzFeed_Real_'+str(i)+'-Webpage.json'\n",
        "    df = pd.read_json(path,orient='index')\n",
        "    df = df.transpose()\n",
        "    bf_real_news = pd.concat([bf_real_news,df])\n",
        "del(df,path,i)\n",
        "\n",
        "#get fake news content data\n",
        "bf_fake_news =  pd.DataFrame(columns=temp.index)\n",
        "for i in range(1,92):\n",
        "    path='BuzzFeed/FakeNewsContent/BuzzFeed_Fake_'+str(i)+'-Webpage.json'\n",
        "    df = pd.read_json(path,orient='index')\n",
        "    df = df.transpose()\n",
        "    bf_fake_news = pd.concat([bf_fake_news, df])\n",
        "del(df,path,i,temp)\n",
        "bf_fake_news['Real'] = 0\n",
        "bf_real_news['Real'] = 1\n",
        "\n",
        "bf_real_news.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "8Lg3fC4R4XIK",
        "outputId": "cc81594a-c0ec-43e0-b122-8c43603fb6dd"
      },
      "outputs": [],
      "source": [
        "bf_fake_news = bf_fake_news.reset_index(drop=True)\n",
        "bf_fake_news.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDVwkdo3lN6H"
      },
      "source": [
        "The BuzzFeed set is organized in the same fashion as the Politifact dataset with the same features. In this set though, we have only 91 stories for each set for a total of 182 stories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpsbi-OtUYXM"
      },
      "source": [
        "### BuzzFeed: Load and Format User/Network Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ekBewJQUgfZ",
        "outputId": "24c7d4a4-dd78-4a10-e780-0dfa9018c6db"
      },
      "outputs": [],
      "source": [
        "# get user info data\n",
        "bf_news = pd.read_csv('BuzzFeed/News.txt',header=None,names=['news'])\n",
        "bf_users = pd.read_csv('BuzzFeed/User.txt',header=None,names=['users'])\n",
        "bf_news_user = pd.read_csv('BuzzFeed/BuzzFeedNewsUser.txt',header=None,names=['news_users'])\n",
        "bf_user_user = pd.read_csv('BuzzFeed/BuzzFeedUserUser.txt',header=None,names=['followers'])\n",
        "\n",
        "# build graph\n",
        "G_bf = nx.DiGraph()\n",
        "G_bf.add_nodes_from(bf_users)\n",
        "G_bf.add_edges_from(bf_user_user['followers'].str.split('\\t'))\n",
        "print('The number of nodes in the network is ',G_bf.number_of_nodes())\n",
        "print('The number of edges in the network is ',G_bf.number_of_edges())\n",
        "print('The number of user-news relationships is', len(bf_news_user))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4HkGb6zkGMu"
      },
      "source": [
        "In this network we have 15,258 distinct twitter users and 634,750 user relationships represented in the data set. Finally there are 22,779 user-news relationships that tell which user shared which story and how many times.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX3jYg6cC60o"
      },
      "source": [
        "## Feature Engineering: Social Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN0XtwEEC71X"
      },
      "source": [
        "### Number of Times Shared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1l8vhbFC7h0"
      },
      "outputs": [],
      "source": [
        "# Politifact\n",
        "pf_news = pd. concat([pf_real_news, pf_fake_news]).reset_index(drop=True)\n",
        "pf_news.index\n",
        "pf_news['news_number']  = pf_news.index +1\n",
        "pf_news_user['news_users']=pf_news_user['news_users'].str.split('\\t')\n",
        "pf_news_user=pf_news_user['news_users'].apply(pd.Series)\n",
        "pf_news_user.rename(columns={0:'news',1:'user',2:'num_shared'},inplace=True)\n",
        "pf_news_user['num_shared'] = pf_news_user['num_shared'].astype('int')\n",
        "pf_news_user['news'] = pf_news_user['news'].astype('int')\n",
        "df=pf_news_user.groupby('news')['num_shared'].sum()\n",
        "df=df.reset_index(drop=True)\n",
        "pf_news['num_shared']=df\n",
        "del(df)\n",
        "pf_news['num_shared'] = pf_news['num_shared'].astype('int')\n",
        "\n",
        "# BuzzFeed\n",
        "bf_news = pd.concat([bf_real_news,bf_fake_news]).reset_index(drop=True)\n",
        "bf_news.index\n",
        "bf_news['news_number']  = bf_news.index +1\n",
        "bf_news['news_number']\n",
        "bf_news_user['news_users']=bf_news_user['news_users'].str.split('\\t')\n",
        "bf_news_user=bf_news_user['news_users'].apply(pd.Series)\n",
        "bf_news_user.rename(columns={0:'news',1:'user',2:'num_shared'},inplace=True)\n",
        "bf_news_user['num_shared'] = bf_news_user['num_shared'].astype('int')\n",
        "bf_news_user['news'] = bf_news_user['news'].astype('int')\n",
        "df=bf_news_user.groupby('news')['num_shared'].sum()\n",
        "df=df.reset_index(drop=True)\n",
        "bf_news['num_shared']=df\n",
        "del(df)\n",
        "bf_news['num_shared'] = bf_news['num_shared'].astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i-E-lvtAz23"
      },
      "source": [
        "### Num Times Shared by top 2 percent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehqy1f85A0N7",
        "outputId": "7c55edbf-2e01-4163-c86b-221079923987"
      },
      "outputs": [],
      "source": [
        "# Politifact\n",
        "degree_cent = nx.in_degree_centrality(G_pf)\n",
        "sort_dict_degree= dict(sorted((value, key) for (key,value) in degree_cent.items())) \n",
        "top= -int(.02*G_pf.number_of_nodes())\n",
        "print(top)\n",
        "temp=list(sort_dict_degree.values())[top:]\n",
        "foo=pf_news_user.loc[pf_news_user['user'].isin(temp),'news'].sort_values()\n",
        "foo1=foo.groupby(foo).count()\n",
        "foo1.index=foo1.index-1\n",
        "pf_news['shared_by_top']=foo1\n",
        "pf_news.loc[pf_news['shared_by_top'].isna(),'shared_by_top']=0\n",
        "# pf_news[['shared_by_top','Real']]\n",
        "\n",
        "# Buzzfeed\n",
        "degree_cent = nx.in_degree_centrality(G_bf)\n",
        "sort_dict_degree= dict(sorted((value, key) for (key,value) in degree_cent.items())) \n",
        "top= -int(.02*G_bf.number_of_nodes())\n",
        "print(top)\n",
        "temp=list(sort_dict_degree.values())[top:]\n",
        "foo=bf_news_user.loc[bf_news_user['user'].isin(temp),'news'].sort_values()\n",
        "foo1=foo.groupby(foo).count()\n",
        "foo1.index=foo1.index-1\n",
        "bf_news['shared_by_top']=foo1\n",
        "bf_news.loc[bf_news['shared_by_top'].isna(),'shared_by_top']=0\n",
        "#bf_news['shared_by_top']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UrHHgSSA-RS"
      },
      "source": [
        "### Avg. Number of Followers Shared by"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JUYQepSA-bu"
      },
      "outputs": [],
      "source": [
        "# Politifact\n",
        "degree=pd.DataFrame.from_dict(G_pf.in_degree).drop(0).rename(columns={0:'user',1:'followers'})\n",
        "degree.reset_index(drop=True,inplace=True)\n",
        "degree['user']=degree['user'].astype('int')\n",
        "pf_news_user['user']=pf_news_user['user'].astype('int')\n",
        "df=degree.merge(pf_news_user,on='user')\n",
        "df=df.groupby('news')['followers'].mean().reset_index()\n",
        "pf_news['avg_follower']=df['followers']\n",
        "del(df)\n",
        "pf_news['avg_follower']\n",
        "\n",
        "# Buzzfeed\n",
        "degree=pd.DataFrame.from_dict(G_bf.in_degree).drop(0).rename(columns={0:'user',1:'followers'})\n",
        "degree.reset_index(drop=True,inplace=True)\n",
        "degree['user']=degree['user'].astype('int')\n",
        "bf_news_user['user']=bf_news_user['user'].astype('int')\n",
        "df=degree.merge(bf_news_user,on='user')\n",
        "df=df.groupby('news')['followers'].mean().reset_index()\n",
        "bf_news['avg_follower']=df['followers']\n",
        "del(df)\n",
        "#bf_news['avg_follower']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbAtAN4fBOzq"
      },
      "source": [
        "### Avg. Number of followees shared by"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8sMBdB_BWgE"
      },
      "outputs": [],
      "source": [
        "# Politifact\n",
        "degree=pd.DataFrame.from_dict(G_pf.out_degree).drop(0).rename(columns={0:'user',1:'followees'})\n",
        "degree.reset_index(drop=True,inplace=True)\n",
        "degree['user']=degree['user'].astype('int')\n",
        "#pf_news_user['user']=pf_news_user['user'].astype('int')\n",
        "df=degree.merge(pf_news_user,on='user')\n",
        "df=df.groupby('news')['followees'].mean().reset_index()\n",
        "pf_news['avg_followee']=df['followees']\n",
        "del(df)\n",
        "#pf_news['avg_followee']\n",
        "\n",
        "# BuzzFeed\n",
        "degree=pd.DataFrame.from_dict(G_bf.out_degree).drop(0).rename(columns={0:'user',1:'followees'})\n",
        "degree.reset_index(drop=True,inplace=True)\n",
        "degree['user']=degree['user'].astype('int')\n",
        "#bf_news_user['user']=bf_news_user['user'].astype('int')\n",
        "df=degree.merge(bf_news_user,on='user')\n",
        "df=df.groupby('news')['followees'].mean().reset_index()\n",
        "bf_news['avg_followee']=df['followees']\n",
        "del(df)\n",
        "#bf_news['avg_followee']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mDEBfr_BZqm"
      },
      "source": [
        "### Followee to Follower Ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEPKq6PvBZ2n"
      },
      "outputs": [],
      "source": [
        "pf_news['f_ratio']=pf_news['avg_followee']/pf_news['avg_follower']\n",
        "bf_news['f_ratio']=bf_news['avg_followee']/bf_news['avg_follower']\n",
        "#bf_news['f_ratio']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df.head()# news = news.append([bf_news,pf_news],ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df['user'] = df.user.astype(int)\n",
        "# df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bf_news_user.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUyuMK64Yom8"
      },
      "outputs": [],
      "source": [
        "# G_bf.degree\n",
        "# G_bf_outD = dict(G_bf.out_degree())\n",
        "# k = [k for k,v in G_bf_outD.items()]\n",
        "# v = [v for k,v in G_bf_outD.items()]\n",
        "# df = pd.DataFrame({'user': k, 'Followers': v, 'Fraction': v/np.sum(v)}).drop(0,axis=0)\n",
        "# df_ = df.merge(bf_news_user, on='user')\n",
        "# bf_news_user.head()\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36504fD1nMZw"
      },
      "outputs": [],
      "source": [
        "G_bf.degree\n",
        "G_bf_inD = dict(G_bf.in_degree())\n",
        "k = [k for k,v in G_bf_inD.items()]\n",
        "v = [v for k,v in G_bf_inD.items()]\n",
        "df = pd.DataFrame({'Users': k, 'Followers': v, 'Fraction': v/np.sum(v)}).drop(0,axis=0)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cOylypfHdXc"
      },
      "source": [
        "**Betweeness Centrality for Buzz Feed**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pw1Y6NQiE2E3"
      },
      "outputs": [],
      "source": [
        "# G_bf_b = nx.betweenness_centrality(G_bf, endpoints=True,normalized=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# new_G_bf_b = G_bf_b.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# new_G_bf_b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8X4S_XCcHqGz"
      },
      "source": [
        "**Closeness Centrality for Buzz Feed**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDBcRsQOtQS8"
      },
      "outputs": [],
      "source": [
        "# G_bf_c = nx.closeness_centrality(G_bf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLsVH4kbHxtB"
      },
      "source": [
        "**Betweenness Centrality for Politifact**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLIfVi95tRvr"
      },
      "outputs": [],
      "source": [
        "# G_pf_b = nx.betweenness_centrality(G_pf, endpoints=True,normalized=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XjwHeq0H7z_"
      },
      "source": [
        "**Closeness Centrality for Politifact**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VARWQyZEs64D"
      },
      "outputs": [],
      "source": [
        "# G_pf_c = nx.closeness_centrality(G_pf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpAaXlx3QeQY"
      },
      "outputs": [],
      "source": [
        "\n",
        "# with open('G_bf_b.csv', 'w') as csv_file:  \n",
        "#     writer = csv.writer(csv_file)\n",
        "#     for key, value in G_bf_b.items():\n",
        "      #  writer.writerow([key, value])\n",
        "with open('Term Project/G_bf_b.csv') as csv_file:\n",
        "    file = csv.reader(csv_file)\n",
        "    G_bf_b = dict(file)\n",
        "# G_bf_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRkRL4BISo3j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rztzJ-kZSmbl"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icyfEtjMQkp4"
      },
      "outputs": [],
      "source": [
        "# with open('G_bf_c.csv', 'w') as csv_file:  \n",
        "#     writer = csv.writer(csv_file)\n",
        "#     for key, value in G_bf_c.items():\n",
        "#        writer.writerow([key, value])\n",
        "with open('Term Project/G_bf_c.csv') as csv_file:\n",
        "    file = csv.reader(csv_file)\n",
        "    G_bf_c  = dict(file)\n",
        "# G_bf_c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ktky6BEROod"
      },
      "outputs": [],
      "source": [
        "# with open('G_pf_b.csv', 'w') as csv_file:  \n",
        "#     writer = csv.writer(csv_file)\n",
        "#     for key, value in G_pf_b .items():\n",
        "#        writer.writerow([key, value])\n",
        "with open('Term Project/G_pf_b.csv') as csv_file:\n",
        "    file = csv.reader(csv_file)\n",
        "    G_pf_b = dict(file)\n",
        "# G_pf_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAZqTKPDROzH"
      },
      "outputs": [],
      "source": [
        "# with open('G_pf_c.csv', 'w') as csv_file:  \n",
        "#     writer = csv.writer(csv_file)\n",
        "#     for key, value in G_pf_c.items():\n",
        "#        writer.writerow([key, value])\n",
        "with open('Term Project/G_pf_c.csv') as csv_file:\n",
        "    file = csv.reader(csv_file)\n",
        "    G_pf_c = dict(file)\n",
        "# G_pf_c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWyFIgk-E4Is"
      },
      "outputs": [],
      "source": [
        "#Buzz Feed betweenness centrality\n",
        "btw_central = G_bf_b\n",
        "\n",
        "k = [k for k,v in btw_central.items()]\n",
        "v = [v for k,v in btw_central.items()]\n",
        "btw_central = pd.DataFrame({'user': k, 'betweenness_centrality': v}).rename(columns = {0:'user',1:'betweenness_centrality'}).drop(0,axis = 0).reset_index()\n",
        "btw_central['user'] = btw_central['user'].astype('i4')\n",
        "btw_central['betweenness_centrality'] = btw_central['betweenness_centrality'].astype('float')\n",
        "df = btw_central.merge(bf_news_user, on = 'user')\n",
        "df = df.groupby('news')['betweenness_centrality'].mean().reset_index()\n",
        "bf_news['betweenness_centrality'] = df['betweenness_centrality']\n",
        "# bf_news.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdLb2htVHLK-"
      },
      "outputs": [],
      "source": [
        "#Buzz Feed closenness centrality\n",
        "close_central = G_bf_c\n",
        "\n",
        "k = [k for k,v in close_central.items()]\n",
        "v = [v for k,v in close_central.items()]\n",
        "\n",
        "close_central  = pd.DataFrame({'user': k, 'closenness_centrality': v}).rename(columns = {0:'user',1:'closenness_centrality'}).drop(0,axis = 0).reset_index()\n",
        "close_central['user'] = close_central['user'].astype('i4')\n",
        "close_central['closenness_centrality'] = close_central['closenness_centrality'].astype('float')\n",
        "df = close_central.merge(bf_news_user, on = 'user')\n",
        "df = df.groupby('news')['closenness_centrality'].mean().reset_index()\n",
        "bf_news['closenness_centrality'] = df['closenness_centrality']\n",
        "# bf_news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWuRuJ6Df_PU"
      },
      "outputs": [],
      "source": [
        "#Plotifact betweenness centrality\n",
        "btw_central = G_pf_b\n",
        "\n",
        "k = [k for k,v in btw_central.items()]\n",
        "v = [v for k,v in btw_central.items()]\n",
        "\n",
        "btw_central = pd.DataFrame({'user': k, 'betweenness_centrality': v}).rename(columns = {0:'user',1:'betweenness_centrality'}).drop(0,axis = 0).reset_index()\n",
        "btw_central['user'] = btw_central['user'].astype('i4')\n",
        "btw_central['betweenness_centrality'] = btw_central['betweenness_centrality'].astype('float')\n",
        "df = btw_central.merge(pf_news_user, on = 'user')\n",
        "df = df.groupby('news')['betweenness_centrality'].mean().reset_index()\n",
        "pf_news['betweenness_centrality'] = df['betweenness_centrality']\n",
        "# pf_news.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6C2sqC9LCWg"
      },
      "outputs": [],
      "source": [
        "#Politifact closeness centrality\n",
        "close_central = G_pf_c\n",
        "\n",
        "k = [k for k,v in close_central.items()]\n",
        "v = [v for k,v in close_central.items()]\n",
        "\n",
        "close_central = pd.DataFrame({'user': k, 'closenness_centrality': v}).rename(columns = {0:'user',1:'closenness_centrality'}).drop(0,axis = 0).reset_index()\n",
        "close_central['user'] = close_central['user'].astype('i4')\n",
        "close_central['closenness_centrality'] = close_central['closenness_centrality'].astype('float')\n",
        "df = close_central.merge(pf_news_user, on = 'user')\n",
        "df = df.groupby('news')['closenness_centrality'].mean().reset_index()\n",
        "pf_news['closenness_centrality'] = df['closenness_centrality']\n",
        "# pf_news"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvKxEVEQHP_z"
      },
      "source": [
        "## Union of News Content Data Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ-KbQUNG3Wr",
        "outputId": "ce575985-898c-4465-8266-edefd14c7891"
      },
      "outputs": [],
      "source": [
        "cols = list(pf_news.columns)\n",
        "news = pd.DataFrame(columns=cols)\n",
        "news = pd.concat([news,bf_fake_news],axis=0,ignore_index=True)\n",
        "news = news.sample(frac=1).reset_index(drop=True)\n",
        "news.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0AcEleF7ckt"
      },
      "source": [
        "Because the four news content datasets have the same fields and do not conatin any information exclusive to the individual datasets, in contrast to the network data, we can merge them into a single dataset for use in our data mining algorithms. This has the positive effect of increasing our sample size to 422 total news stories. The ratio of true stories to false stories is 50:50. Note that we added a logical variable 'Real' to indicate whether the story is real or fake and the order of the instances has been randomized to eliminate patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV-KK3MrRAq8"
      },
      "source": [
        "## Feature Engineering: News Content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EwuMlCxm9vT",
        "outputId": "519ea0ce-8c70-4ffd-9cd8-0c935d478323"
      },
      "outputs": [],
      "source": [
        "import emoji\n",
        "# from emoji import UNICODE_EMOJI\n",
        "from emoji import unicode_codes\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize  \n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# list(emoji.unicode_codes.EMOJI_DATA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUgA6dFMKiMR"
      },
      "outputs": [],
      "source": [
        "def num_all_caps(string):\n",
        "    if len(re.findall(r\"([A-Z]+\\s?[A-Z]+[^a-z0-9\\W])\",string)) > 0:\n",
        "      return 0\n",
        "    return 1\n",
        "    # return len(re.findall(r\"([A-Z]+\\s?[A-Z]+[^a-z0-9\\W])\",string))\n",
        "def num_exmarks(string):\n",
        "    if string.count(\"!\") > 0:\n",
        "      return 0\n",
        "    return 1\n",
        "    # return string.count(\"!\") \n",
        "\n",
        "def num_all_caps_or_exmarks(string):\n",
        "    if len(re.findall(r\"([A-Z]+\\s?[A-Z]+[^a-z0-9\\W])\",string)) > 0:\n",
        "      return 0\n",
        "    if string.count(\"!\") > 0:\n",
        "      return 0\n",
        "    return 1\n",
        "\n",
        "def title_ln(text):\n",
        "  totalln = 0 \n",
        "  for character in word_tokenize(text):\n",
        "      totalln +=1\n",
        "  if totalln > 11:\n",
        "    return 0\n",
        "  return 1\n",
        "  # return totalln\n",
        "def text_ln(text):\n",
        "  totalln = 0 \n",
        "  for character in word_tokenize(text):\n",
        "      totalln +=1\n",
        "  if totalln > 500:\n",
        "    return 1\n",
        "  return 0\n",
        "  # return totalln\n",
        "def text_has_emoji(text):\n",
        "    for character in text:\n",
        "        if character in list(emoji.unicode_codes.EMOJI_DATA):\n",
        "            return 1\n",
        "    return 0\n",
        "def text_word_len(text):\n",
        "  longln = 0\n",
        "  totalln = 0 \n",
        "  for character in word_tokenize(text):\n",
        "    if character not in stop_words:\n",
        "      if len(character) > 6:\n",
        "        longln += 1\n",
        "      totalln +=1\n",
        "  if totalln != 0:\n",
        "    if longln / totalln > 0.3:\n",
        "      return 0\n",
        "  return 1\n",
        "  # if totalln != 0:\n",
        "  #   return longln / totalln\n",
        "  # return 0\n",
        "def stop_word_title(text):\n",
        "  stopln = 0\n",
        "  totalln = 0 \n",
        "  for character in word_tokenize(text):\n",
        "    if character in stop_words:\n",
        "        stopln += 1\n",
        "    totalln +=1\n",
        "  if totalln != 0:\n",
        "    if stopln / totalln > 0.14:\n",
        "      return 1\n",
        "  return 0\n",
        "  # if totalln != 0:\n",
        "  #   return stopln / totalln\n",
        "  # return 0\n",
        "def stop_word_text(text):\n",
        "  stopln = 0\n",
        "  totalln = 0 \n",
        "  for character in word_tokenize(text):\n",
        "    if character in stop_words:\n",
        "        stopln += 1\n",
        "    totalln +=1\n",
        "  if totalln != 0:\n",
        "    if stopln / totalln > 0.37:\n",
        "      return 1\n",
        "  return 0\n",
        "  # if totalln != 0:\n",
        "  #   return stopln / totalln\n",
        "  # return 0\n",
        "news['title_allcaps']=news['title'].apply(num_all_caps)\n",
        "news['title_num_exmarks'] = news['title'].apply(num_exmarks)\n",
        "news['title_allcaps_or_exmarks']=news['title'].apply(num_all_caps_or_exmarks)\n",
        "news['title_length']=news['title'].apply(title_ln)\n",
        "news['text_length']=news['text'].apply(text_ln)\n",
        "news['title_isascii']=news['title'].apply(text_has_emoji)\n",
        "news['text_isascii']=news['text'].apply(text_has_emoji)\n",
        "news['title_comp']=news['title'].apply(text_word_len)\n",
        "news['text_comp']=news['text'].apply(text_word_len)\n",
        "news['title_stopwords']=news['title'].apply(stop_word_title)\n",
        "news['text_stopwords']=news['text'].apply(stop_word_text)\n",
        "# Readability Scores\n",
        "# news['flesch_score'] =news['text'].apply(ts.flesch_reading_ease).apply(lambda x: x**2)\n",
        "news['flesch_score'] =news['text'].apply(ts.flesch_reading_ease)\n",
        "news['dale_chall_score'] =news['text'].apply(ts.dale_chall_readability_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK3LYP23RLuF"
      },
      "source": [
        "## Prepare Data Set for Data Mining"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbAXVqKMOINe"
      },
      "source": [
        "### Select Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGgLVU7MCpYA",
        "outputId": "17773ee5-c1ab-4642-bb12-fb35354abb58"
      },
      "outputs": [],
      "source": [
        "feature_list = ['title_isascii','title_allcaps','title_num_exmarks','title_length',\n",
        "               'text_length','flesch_score','dale_chall_score', 'title_comp', \n",
        "                'text_comp', 'title_stopwords', 'text_stopwords', 'num_shared',\n",
        "               'shared_by_top','avg_follower', 'avg_followee', 'f_ratio',\n",
        "                'betweenness_centrality','closenness_centrality','Real',\"title_allcaps_or_exmarks\"]\n",
        "news_ft = news[feature_list].copy()\n",
        "# news_ft['num_shared']=news_ft['num_shared'].astype('int')\n",
        "news_ft['Real']=news_ft['Real'].astype('int')\n",
        "news_ft.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4bCd-w1NKek"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCcWSGmTpPi8"
      },
      "outputs": [],
      "source": [
        "\n",
        "metrics_dict={\n",
        "'Logistic Regression':{'accuracy':0,'precision':0,'recall':0,'f1':0},\n",
        "'XgBoost':{'accuracy':0,'precision':0,'recall':0,'f1':0},\n",
        "'Naive Bayes':{'accuracy':0,'precision':0,'recall':0,'f1':0},\n",
        "'Support Vector Machine':{'accuracy':0,'precision':0,'recall':0,'f1':0},\n",
        "'Decision Tree':{'accuracy':0,'precision':0,'recall':0,'f1':0},\n",
        "'Random Forest Classifier':{'accuracy':0,'precision':0,'recall':0,'f1':0},\n",
        "'Voting Classifier':{'accuracy':0,'precision':0,'recall':0,'f1':0}}\n",
        "\n",
        "metrics_df = pd.DataFrame.from_dict(metrics_dict,orient='index')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU_7VK7sQNBE"
      },
      "source": [
        "### Using Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AZ389chtmve",
        "outputId": "ae5bb58b-e03c-492f-96e6-99f5f20c4f66"
      },
      "outputs": [],
      "source": [
        "# X_ft = news_ft.drop(columns=['Real'])\n",
        "X_ft = news_ft[[          \n",
        "          'text_length',\n",
        "          # 'flesch_score',\n",
        "          'dale_chall_score',\n",
        "          # 'num_shared',\n",
        "          # 'avg_follower',\n",
        "          # 'avg_followee',\n",
        "          # 'closenness_centrality',\n",
        "          # 'betweenness_centrality',\n",
        "          # 'title_allcaps',\n",
        "          'title_allcaps_or_exmarks',\n",
        "\n",
        "          # 'title_num_exmarks',\n",
        "          'title_length',\n",
        "          'shared_by_top',\n",
        "          'title_comp', \n",
        "          'text_comp', \n",
        "          'title_stopwords', \n",
        "          'text_stopwords',\n",
        "          'f_ratio',\n",
        "          ]]\n",
        "y = news_ft['Real']\n",
        "count = CountVectorizer(stop_words='english')\n",
        "X_txt = count.fit_transform(news['text'])\n",
        "X_txt = X_txt.todense()\n",
        "\n",
        "X = np.hstack((X_ft,X_txt))\n",
        "X=X.astype('float')\n",
        "X = X[~np.isnan(X)]\n",
        "# X\n",
        "y = y.astype('int')\n",
        "\n",
        "try:\n",
        "    from sklearn.utils._testing import ignore_warnings\n",
        "except ImportError:\n",
        "    from sklearn.utils.testing import ignore_warnings\n",
        "\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "# warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "# warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "\n",
        "precision_list=[]\n",
        "recall_list=[]\n",
        "f1_list=[]\n",
        "accuracy_list=[]\n",
        "auc_scores = []\n",
        "AVG_precision_scores = []\n",
        "\n",
        "# X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "\n",
        "for tr_ind, tst_ind in skf.split(X,y):\n",
        "    X_train = X[tr_ind]\n",
        "    X_test = X[tst_ind]\n",
        "    y_train = y[tr_ind]\n",
        "    y_test = y[tst_ind]\n",
        "    #classification\n",
        "    lg_clf = LogisticRegression(max_iter=200)\n",
        "    lg_clf.fit(X_train, y_train)  \n",
        "    # predict the labels on test dataset\n",
        "    predictions = lg_clf.predict(X_test)\n",
        "\n",
        "    #evaluation\n",
        "    precision_list.append(metrics.precision_score(y_test, predictions))\n",
        "    recall_list.append(metrics.recall_score(y_test, predictions))\n",
        "    f1_list.append(metrics.f1_score(y_test, predictions))\n",
        "    accuracy_list.append(metrics.accuracy_score(y_test,predictions))\n",
        "    auc_scores.append(roc_auc_score(y_test, predictions))\n",
        "    AVG_precision_scores.append(average_precision_score(y_test, predictions))\n",
        "#     print(metrics.confusion_matrix(y_test,predictions))\n",
        "metrics_df.loc['Logistic Regression','precision'] = round(np.mean(precision_list)*100,3)\n",
        "metrics_df.loc['Logistic Regression','recall'] = round(np.mean(recall_list)*100,3)\n",
        "metrics_df.loc['Logistic Regression','f1'] = round(np.mean(f1_list)*100,3)\n",
        "metrics_df.loc['Logistic Regression','accuracy'] = round(np.mean(accuracy_list)*100,3)\n",
        "print(\" precision  = \", round(np.mean(precision_list)*100,3),\"\\n\", \n",
        "      \"recall     = \",round(np.mean(recall_list)*100,3),\"\\n\",\n",
        "      \"f1         = \",round(np.mean(f1_list)*100,3),\"\\n\",\n",
        "      \"accuracy   = \",round(np.mean(accuracy_list)*100,3),\"\\n\", \n",
        "      \"AUROC      = \", round(np.mean(auc_scores)*100,3),\"\\n\",\n",
        "      \"Average Precision = \", round(np.mean(AVG_precision_scores)*100,3),\"\\n\", )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4dhCANC2_sY"
      },
      "source": [
        "### XG Boost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThSlfP9stnDh",
        "outputId": "2e0d8e70-18ca-44c0-9348-35c2a93a36cc"
      },
      "outputs": [],
      "source": [
        "#X= news_ft.drop(columns=['Real'])\n",
        "X_ft = news_ft[[          \n",
        "          'text_length',\n",
        "          'flesch_score',\n",
        "          'dale_chall_score',\n",
        "          # 'num_shared',\n",
        "          # 'avg_follower',\n",
        "          # 'avg_followee',\n",
        "          # 'closenness_centrality',\n",
        "          # 'betweenness_centrality',\n",
        "          # 'title_allcaps',\n",
        "          'title_allcaps_or_exmarks',\n",
        "          'title_num_exmarks',\n",
        "          'title_length',\n",
        "          'shared_by_top',\n",
        "          'title_comp', \n",
        "          'text_comp', \n",
        "          'title_stopwords', \n",
        "          'text_stopwords',\n",
        "          'f_ratio',\n",
        "          ]]\n",
        "y = news_ft['Real']\n",
        "# y = news['Real']\n",
        "\n",
        "count = CountVectorizer(stop_words='english')\n",
        "X_txt = count.fit_transform(news['text'])\n",
        "X_txt = X_txt.todense()\n",
        "\n",
        "X = np.hstack((X_ft,X_txt))\n",
        "X=X.astype('float')\n",
        "y = y.astype('int')\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "\n",
        "precision_list=[]\n",
        "recall_list=[]\n",
        "f1_list=[]\n",
        "accuracy_list=[]\n",
        "\n",
        "#X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "\n",
        "\n",
        "param = {'max_depth': 2, 'eta': 1, 'objective': 'binary:logistic'}\n",
        "param['nthread'] = 4\n",
        "param['eval_metric'] = 'error'\n",
        "num_round = 10\n",
        "\n",
        "for tr_ind, tst_ind in skf.split(X,y):\n",
        "    X_train = X[tr_ind,:]\n",
        "    X_test = X[tst_ind,:]\n",
        "    y_train = y[tr_ind]\n",
        "    y_test = y[tst_ind]\n",
        "    # evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
        "    #classification\n",
        "    xg_clf = xg.XGBClassifier(max_depth=10, learning_rate=0.5, n_estimators=8,\n",
        "                       objective='binary:logistic', booster='gbtree',min_child_weight=10)\n",
        "    xg_clf.fit(X_train, y_train)  \n",
        "    # predict the labels on test dataset\n",
        "    predictions = xg_clf.predict(X_test)\n",
        "\n",
        "    #evaluation\n",
        "    precision_list.append(metrics.precision_score(y_test, predictions))\n",
        "    recall_list.append(metrics.recall_score(y_test, predictions))\n",
        "    f1_list.append(metrics.f1_score(y_test, predictions))\n",
        "    accuracy_list.append(metrics.accuracy_score(y_test,predictions))\n",
        "    auc_scores.append(roc_auc_score(y_test, predictions))\n",
        "    AVG_precision_scores.append(average_precision_score(y_test, predictions))\n",
        "\n",
        "metrics_df.loc['XgBoost','precision'] =  round(np.mean(precision_list)*100,3)\n",
        "metrics_df.loc['XgBoost','recall'] = round(np.mean(recall_list)*100,3)\n",
        "metrics_df.loc['XgBoost','f1'] = round(np.mean(f1_list)*100,3)\n",
        "metrics_df.loc['XgBoost','accuracy'] = round(np.mean(accuracy_list)*100,3)\n",
        "\n",
        "print(\" precision  = \", round(np.mean(precision_list)*100,3),\"\\n\", \n",
        "      \"recall     = \",round(np.mean(recall_list)*100,3),\"\\n\",\n",
        "      \"f1         = \",round(np.mean(f1_list)*100,3),\"\\n\",\n",
        "      \"accuracy   = \",round(np.mean(accuracy_list)*100,3),\"\\n\", \n",
        "      \"AUROC      = \", round(np.mean(auc_scores)*100,3),\"\\n\",\n",
        "      \"Average Precision = \", round(np.mean(AVG_precision_scores)*100,3),\"\\n\", )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e48avN81JxLu"
      },
      "source": [
        "### Naive Bayes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmBMmuAotWk6"
      },
      "outputs": [],
      "source": [
        "wordCount = CountVectorizer(stop_words='english')\n",
        "wordCount = wordCount.fit(news['text'])\n",
        "text_vector = wordCount.transform(news['text'])\n",
        "\n",
        "temp = text_vector.toarray()\n",
        "text_vector_df = pd.DataFrame(temp, columns=[f'TV{i}' for i in range(15428)], index=news.index)\n",
        "new_df = news_ft.join(text_vector_df, on = news_ft.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIs8_qeBdMKe",
        "outputId": "9202c677-80b6-4a7a-dfc4-35d63fec28f1"
      },
      "outputs": [],
      "source": [
        "# X = text_vector_df.join(news_ft[['title_allcaps','dale_chall_score','title_num_exmarks','f_ratio','shared_by_top', \n",
        "#                         'title_allcaps_or_exmarks','title_comp', 'text_comp', 'title_stopwords', 'text_stopwords']], on=news_ft.index)\n",
        "X = text_vector_df.join(news_ft[['title_allcaps','dale_chall_score','title_num_exmarks','f_ratio','shared_by_top']], on=news_ft.index)\n",
        "\n",
        "y = new_df['Real'].astype('i4')\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "\n",
        "precision_list=[]\n",
        "recall_list=[]\n",
        "f1_list=[]\n",
        "accuracy_list=[]\n",
        "auc_scores = []\n",
        "AVG_precision_scores = []\n",
        "\n",
        "\n",
        "for tr_ind, tst_ind in skf.split(X,y):\n",
        "  X_train = X.iloc[tr_ind]\n",
        "  X_test = X.iloc[tst_ind]\n",
        "  y_train = y[tr_ind]\n",
        "  y_test = y[tst_ind]\n",
        "\n",
        "  mn_clf = MultinomialNB()\n",
        "  mn_clf.fit(X_train, y_train) \n",
        "  predictions = mn_clf.predict(X_test)\n",
        "  proba = mn_clf.predict_proba(X_test)[:,1]\n",
        "      \n",
        "\n",
        "    #evaluation\n",
        "  precision = metrics.precision_score(y_test, predictions)\n",
        "  recall = metrics.recall_score(y_test, predictions)\n",
        "  f1 = metrics.f1_score(y_test, predictions)\n",
        "  accuracy = metrics.accuracy_score(y_test,predictions)\n",
        "      # print(metrics.confusion_matrix(y_test,predictions))\n",
        "      \n",
        "  precision_list.append(precision)\n",
        "  recall_list.append(recall)\n",
        "  f1_list.append(f1)\n",
        "  accuracy_list.append(accuracy)\n",
        "  auc_scores.append(roc_auc_score(y_test, proba))\n",
        "  AVG_precision_scores.append(average_precision_score(y_test, proba))\n",
        "\n",
        "metrics_df.loc['Naive Bayes','precision'] = round(np.mean(precision_list)*100,3)\n",
        "metrics_df.loc['Naive Bayes','recall'] = round(np.mean(recall_list)*100,3)\n",
        "metrics_df.loc['Naive Bayes','f1'] = round(np.mean(f1_list)*100,3)\n",
        "metrics_df.loc['Naive Bayes','accuracy'] = round(np.mean(accuracy_list)*100,3)\n",
        "\n",
        "print(\" precision  = \", round(np.mean(precision_list)*100,3),\"\\n\", \n",
        "      \"recall     = \",round(np.mean(recall_list)*100,3),\"\\n\",\n",
        "      \"f1         = \",round(np.mean(f1_list)*100,3),\"\\n\",\n",
        "      \"accuracy   = \",round(np.mean(accuracy_list)*100,3),\"\\n\", \n",
        "      \"AUROC      = \", round(np.mean(auc_scores)*100,3),\"\\n\",\n",
        "      \"Average Precision = \", round(np.mean(AVG_precision_scores)*100,3),\"\\n\", )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIdRpo8fInRh"
      },
      "source": [
        "### Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaIu4NaErpD4"
      },
      "outputs": [],
      "source": [
        "wordCount = TfidfVectorizer(stop_words='english')\n",
        "wordCount = wordCount.fit(news['text'])\n",
        "text_vector = wordCount.transform(news['text'])\n",
        "\n",
        "temp = text_vector.toarray()\n",
        "text_vector_df = pd.DataFrame(temp, columns=[f'TV{i}' for i in range(15428)], index=news.index)\n",
        "new_df = news_ft.join(text_vector_df, on = news_ft.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T684m_EhIrPv",
        "outputId": "28961095-5a30-49b5-d027-b017b0e2e5d7"
      },
      "outputs": [],
      "source": [
        "X = text_vector_df.join(news_ft[['title_allcaps','dale_chall_score','title_num_exmarks','f_ratio','shared_by_top',\n",
        "          'title_comp', 'text_comp', 'title_stopwords', 'text_stopwords']], on=news_ft.index)\n",
        "y = new_df['Real'].astype('i4')\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "\n",
        "precision_list=[]\n",
        "recall_list=[]\n",
        "f1_list=[]\n",
        "accuracy_list=[]\n",
        "auc_scores = []\n",
        "AVG_precision_scores = []\n",
        "\n",
        "\n",
        "for tr_ind, tst_ind in skf.split(X,y):\n",
        "  X_train = X.iloc[tr_ind]\n",
        "  X_test = X.iloc[tst_ind]\n",
        "  y_train = y[tr_ind]\n",
        "  y_test = y[tst_ind]\n",
        "\n",
        "  sv_clf = svm.SVC(kernel= 'rbf', class_weight='balanced',probability=True, decision_function_shape='ovo',C=85)\n",
        "  sv_clf.fit(X_train, y_train) \n",
        "  predictions = sv_clf.predict(X_test)\n",
        "  proba = sv_clf.predict_proba(X_test)[:,1]\n",
        "      \n",
        "\n",
        "    #evaluation\n",
        "  precision = metrics.precision_score(y_test, predictions)\n",
        "  recall = metrics.recall_score(y_test, predictions)\n",
        "  f1 = metrics.f1_score(y_test, predictions)\n",
        "  accuracy = metrics.accuracy_score(y_test,predictions)\n",
        "      # print(metrics.confusion_matrix(y_test,predictions))\n",
        "      \n",
        "  precision_list.append(precision)\n",
        "  recall_list.append(recall)\n",
        "  f1_list.append(f1)\n",
        "  accuracy_list.append(accuracy)\n",
        "  auc_scores.append(roc_auc_score(y_test, proba))\n",
        "  AVG_precision_scores.append(average_precision_score(y_test, proba))\n",
        "\n",
        "metrics_df.loc['Support Vector Machine','precision'] = round(np.mean(precision_list)*100,3)\n",
        "metrics_df.loc['Support Vector Machine','recall'] = round(np.mean(recall_list)*100,3)\n",
        "metrics_df.loc['Support Vector Machine','f1'] = round(np.mean(f1_list)*100,3)\n",
        "metrics_df.loc['Support Vector Machine','accuracy'] = round(np.mean(accuracy_list)*100,3)\n",
        "\n",
        "print(\" precision  = \", round(np.mean(precision_list)*100,3),\"\\n\", \n",
        "      \"recall     = \",round(np.mean(recall_list)*100,3),\"\\n\",\n",
        "      \"f1         = \",round(np.mean(f1_list)*100,3),\"\\n\",\n",
        "      \"accuracy   = \",round(np.mean(accuracy_list)*100,3),\"\\n\", \n",
        "      \"AUROC      = \", round(np.mean(auc_scores)*100,3),\"\\n\",\n",
        "      \"Average Precision = \", round(np.mean(AVG_precision_scores)*100,3),\"\\n\", )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvejxVtifgfn"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cisVMj2nfp5h",
        "outputId": "5f4e57ec-5a00-4312-c9e1-840fbe92ef20"
      },
      "outputs": [],
      "source": [
        "wordCount = CountVectorizer(stop_words='english')\n",
        "wordCount = wordCount.fit(news['text'])\n",
        "text_vector = wordCount.transform(news['text'])\n",
        "tnew = news.copy()\n",
        "\n",
        "temp = text_vector.toarray()\n",
        "text_vector_df = pd.DataFrame(temp, columns=[f'TV{i}' for i in range(15428)], index=news.index)\n",
        "new_df = news_ft.join(text_vector_df, on = news_ft.index)\n",
        "X = text_vector_df.join(news_ft[[          \n",
        "          'text_length',\n",
        "          # 'flesch_score',\n",
        "          'dale_chall_score',\n",
        "          # 'num_shared',\n",
        "          # 'avg_follower',\n",
        "          # 'avg_followee',\n",
        "          'closenness_centrality',\n",
        "          # 'betweenness_centrality',\n",
        "          # 'title_allcaps',\n",
        "          'title_allcaps_or_exmarks',\n",
        "          # 'title_num_exmarks',\n",
        "          # 'title_length',\n",
        "          'shared_by_top',\n",
        "          'title_comp', \n",
        "          'text_comp', \n",
        "          # 'title_stopwords', \n",
        "          # 'text_stopwords',\n",
        "          # 'f_ratio',\n",
        "          ]], on=news_ft.index)\n",
        "y = tnew['Real'].astype('i4')\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "\n",
        "precision_list=[]\n",
        "recall_list=[]\n",
        "f1_list=[]\n",
        "accuracy_list=[]\n",
        "auc_scores = []\n",
        "AVG_precision_scores = []\n",
        "\n",
        "\n",
        "for tr_ind, tst_ind in skf.split(X,y):\n",
        "  X_train = X.iloc[tr_ind]\n",
        "  X_test = X.iloc[tst_ind]\n",
        "  y_train = y[tr_ind]\n",
        "  y_test = y[tst_ind]\n",
        "\n",
        "  tr_clf = DecisionTreeClassifier( )\n",
        "  tr_clf = tr_clf.fit(X_train, y_train)\n",
        "  predictions = tr_clf.predict(X_test)\n",
        "  proba = tr_clf.predict_proba(X_test)[:,1]\n",
        "      \n",
        "\n",
        "    #evaluation\n",
        "  precision = metrics.precision_score(y_test, predictions)\n",
        "  recall = metrics.recall_score(y_test, predictions)\n",
        "  f1 = metrics.f1_score(y_test, predictions)\n",
        "  accuracy = metrics.accuracy_score(y_test,predictions)\n",
        "      # print(metrics.confusion_matrix(y_test,predictions))\n",
        "      \n",
        "  precision_list.append(precision)\n",
        "  recall_list.append(recall)\n",
        "  f1_list.append(f1)\n",
        "  accuracy_list.append(accuracy)\n",
        "  auc_scores.append(roc_auc_score(y_test, proba))\n",
        "  AVG_precision_scores.append(average_precision_score(y_test, proba))\n",
        "\n",
        "metrics_df.loc['Decision Tree','precision'] = round(np.mean(precision_list)*100,3)\n",
        "metrics_df.loc['Decision Tree','recall'] = round(np.mean(recall_list)*100,3)\n",
        "metrics_df.loc['Decision Tree','f1'] = round(np.mean(f1_list)*100,3)\n",
        "metrics_df.loc['Decision Tree','accuracy'] = round(np.mean(accuracy_list)*100,3)\n",
        "\n",
        "print(\" precision  = \", round(np.mean(precision_list)*100,3),\"\\n\", \n",
        "      \"recall     = \",round(np.mean(recall_list)*100,3),\"\\n\",\n",
        "      \"f1         = \",round(np.mean(f1_list)*100,3),\"\\n\",\n",
        "      \"accuracy   = \",round(np.mean(accuracy_list)*100,3),\"\\n\", \n",
        "      \"AUROC      = \", round(np.mean(auc_scores)*100,3),\"\\n\",\n",
        "      \"Average Precision = \", round(np.mean(AVG_precision_scores)*100,3),\"\\n\", )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmH5FQItgEcK"
      },
      "source": [
        "### Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xs0-zHFgMge",
        "outputId": "b73979c7-e47b-4e6f-ee91-3e5f7dccdbd4"
      },
      "outputs": [],
      "source": [
        "X = text_vector_df.join(news_ft[[          \n",
        "          # 'title_allcaps',\n",
        "          'title_allcaps_or_exmarks',\n",
        "          # 'title_num_exmarks',\n",
        "\n",
        "          'title_length',\n",
        "          # 'text_length',\n",
        "\n",
        "          # 'flesch_score',\n",
        "\n",
        "          'dale_chall_score',\n",
        "          # 'num_shared',\n",
        "\n",
        "          'shared_by_top',\n",
        "          'avg_follower',\n",
        "          'title_comp', \n",
        "\n",
        "          'text_comp', \n",
        "          'title_stopwords', \n",
        "          # 'text_stopwords',\n",
        "          # 'avg_followee',\n",
        "          'f_ratio',\n",
        "          # 'closenness_centrality',\n",
        "          # 'betweenness_centrality',\n",
        "          ]], on=news_ft.index)\n",
        "y = tnew['Real'].astype('i4')\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "\n",
        "precision_list=[]\n",
        "recall_list=[]\n",
        "f1_list=[]\n",
        "accuracy_list=[]\n",
        "auc_scores = []\n",
        "AVG_precision_scores = []\n",
        "\n",
        "\n",
        "for tr_ind, tst_ind in skf.split(X,y):\n",
        "  X_train = X.iloc[tr_ind]\n",
        "  X_test = X.iloc[tst_ind]\n",
        "  y_train = y[tr_ind]\n",
        "  y_test = y[tst_ind]\n",
        "\n",
        "  rnd_clf = RandomForestClassifier(n_estimators= 1000)\n",
        "  rnd_clf = rnd_clf.fit(X_train, y_train)\n",
        "  predictions = rnd_clf.predict(X_test)\n",
        "  proba = rnd_clf.predict_proba(X_test)[:,1]\n",
        "      \n",
        "\n",
        "    #evaluation\n",
        "  precision = metrics.precision_score(y_test, predictions)\n",
        "  recall = metrics.recall_score(y_test, predictions)\n",
        "  f1 = metrics.f1_score(y_test, predictions)\n",
        "  accuracy = metrics.accuracy_score(y_test,predictions)\n",
        "      # print(metrics.confusion_matrix(y_test,predictions))\n",
        "      \n",
        "  precision_list.append(precision)\n",
        "  recall_list.append(recall)\n",
        "  f1_list.append(f1)\n",
        "  accuracy_list.append(accuracy)\n",
        "  auc_scores.append(roc_auc_score(y_test, proba))\n",
        "  AVG_precision_scores.append(average_precision_score(y_test, proba))\n",
        "\n",
        "metrics_df.loc['Random Forest Classifier','precision'] = round(np.mean(precision_list)*100,3)\n",
        "metrics_df.loc['Random Forest Classifier','recall'] = round(np.mean(recall_list)*100,3)\n",
        "metrics_df.loc['Random Forest Classifier','f1'] = round(np.mean(f1_list)*100,3)\n",
        "metrics_df.loc['Random Forest Classifier','accuracy'] = round(np.mean(accuracy_list)*100,3)\n",
        "\n",
        "print(\" precision  = \", round(np.mean(precision_list)*100,3),\"\\n\", \n",
        "      \"recall     = \",round(np.mean(recall_list)*100,3),\"\\n\",\n",
        "      \"f1         = \",round(np.mean(f1_list)*100,3),\"\\n\",\n",
        "      \"accuracy   = \",round(np.mean(accuracy_list)*100,3),\"\\n\", \n",
        "      \"AUROC      = \", round(np.mean(auc_scores)*100,3),\"\\n\",\n",
        "      \"Average Precision = \", round(np.mean(AVG_precision_scores)*100,3),\"\\n\", )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUCVAprTeJzU"
      },
      "source": [
        "### Voting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv5EJW1h-4QG",
        "outputId": "73194d20-59dc-4fa8-ae11-e42a814f9ff1"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "X = text_vector_df.join(news_ft[['title_allcaps','title_isascii','dale_chall_score','title_num_exmarks','f_ratio','shared_by_top',\n",
        "                      'title_comp', 'text_comp', 'title_stopwords', 'text_stopwords']], on=news_ft.index)\n",
        "y = new_df['Real'].astype('i4')\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "\n",
        "precision_list=[]\n",
        "recall_list=[]\n",
        "f1_list=[]\n",
        "accuracy_list=[]\n",
        "auc_scores = []\n",
        "AVG_precision_scores = []\n",
        "\n",
        "\n",
        "for tr_ind, tst_ind in skf.split(X,y):\n",
        "  X_train = X.iloc[tr_ind]\n",
        "  X_test = X.iloc[tst_ind]\n",
        "  y_train = y[tr_ind]\n",
        "  y_test = y[tst_ind]\n",
        "\n",
        "  # clf = svm.SVC(kernel= 'rbf', class_weight='balanced',probability=True, decision_function_shape='ovo',C=85)\n",
        "  # clf.fit(X_train, y_train) \n",
        "\n",
        "  log_clf_ = LogisticRegression(max_iter=200)\n",
        "  NV_clf_ = MultinomialNB()\n",
        "  svm_clf_ = svm.SVC(kernel= 'rbf', class_weight='balanced',probability=True, decision_function_shape='ovo',C=85)\n",
        "  tr_clf_ = RandomForestClassifier(n_estimators=1000)\n",
        "  xg_clf_ = xg.XGBClassifier(max_depth=10, learning_rate=0.5, n_estimators=8,\n",
        "                       objective='binary:logistic', booster='gbtree',min_child_weight=10)\n",
        "\n",
        "\n",
        "  vtg_clf = VotingClassifier(\n",
        "      estimators=[('lr', log_clf_), ('NV', NV_clf_),('forest', tr_clf_)],voting='soft')\n",
        "\n",
        "  vtg_clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "  predictions = vtg_clf.predict(X_test)\n",
        "  proba = vtg_clf.predict_proba(X_test)[:,1]\n",
        "      \n",
        "\n",
        "    #evaluation\n",
        "  precision = metrics.precision_score(y_test, predictions)\n",
        "  recall = metrics.recall_score(y_test, predictions)\n",
        "  f1 = metrics.f1_score(y_test, predictions)\n",
        "  accuracy = metrics.accuracy_score(y_test,predictions)\n",
        "      # print(metrics.confusion_matrix(y_test,predictions))\n",
        "      \n",
        "  precision_list.append(precision)\n",
        "  recall_list.append(recall)\n",
        "  f1_list.append(f1)\n",
        "  accuracy_list.append(accuracy)\n",
        "  auc_scores.append(roc_auc_score(y_test, proba))\n",
        "  AVG_precision_scores.append(average_precision_score(y_test, proba))\n",
        "\n",
        "\n",
        "metrics_df.loc['Voting Classifier','precision'] = round(np.mean(precision_list)*100,3)\n",
        "metrics_df.loc['Voting Classifier','recall'] = round(np.mean(recall_list)*100,3)\n",
        "metrics_df.loc['Voting Classifier','f1'] = round(np.mean(f1_list)*100,3)\n",
        "metrics_df.loc['Voting Classifier','accuracy'] = round(np.mean(accuracy_list)*100,3)\n",
        "\n",
        "print(\" precision  = \", round(np.mean(precision_list)*100,3),\"\\n\", \n",
        "      \"recall     = \",round(np.mean(recall_list)*100,3),\"\\n\",\n",
        "      \"f1         = \",round(np.mean(f1_list)*100,3),\"\\n\",\n",
        "      \"accuracy   = \",round(np.mean(accuracy_list)*100,3),\"\\n\", \n",
        "      \"AUROC      = \", round(np.mean(auc_scores)*100,3),\"\\n\",\n",
        "      \"Average Precision = \", round(np.mean(AVG_precision_scores)*100,3),\"\\n\", )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkYiCSXd1eSb"
      },
      "source": [
        "## Summary of Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "HOb_huJihKvW",
        "outputId": "f2b716bd-b09f-4f72-811b-8ecb53375c4a"
      },
      "outputs": [],
      "source": [
        "metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3Nfuk1xmF1t"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('dsb')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "8bee33690903381dd105b525ae0551d31ce430bb6c8585d7109958867dd375a1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
